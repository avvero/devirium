Существует разные подходы к выбору обьемк тестов и акцентов 
Я бы хотел рассказать почему я пришел к трофи. Я бы не хотел пытаться продавать и у меня нет полной уверенности что подобный подход подойдет всем и будте осторожны влюбиться или быть с лишком эксайтет, возможно предложенный вариант будет выглядеть отлично, но вам навредит. 
Я постараюсь описать сценарии, что для меня важны и 

Нужно описать что есть инпут и моки, это создает общий инпут

Далеко я хочу привести несколько примеров, которые меня подтолкнули писать интеграционные:
отказаться от постмана
ревью
баги
онбординг 
документация

Постман
Отличный инструмент, иногда им пользуюсь, но в свое время я пришел к тому что при работе над задачей я снова и снова руками прогоняю одни и те же сценарии. В то время я работал над задачей регистрации клиентов. Я свою фичу и проверял базовые сценарии, т.е регресс. Я думаю каждый из команды делал так же. В какой то момент я просто устал, устал от монотонной генерации уникальных идентификаторов, ручной проверки тех же сценариев. Некоторые из них были многошаговые.

Ревью
Проект большой и я чаще не помню как и что гдетнаписано, но хорошо ориентируюсь в контракте - что сервис делает и как «отвечает» на тот или иной параметр. Например если указана дата рождения и человеку меньше 18, мы ему откажем в обслуживании и предложим демо режим. 
У нас было правило - отдавать ревью чужих задач больший приоритет чем текущим своим. Ревью чужого кода всегда было делом ужасно скучным. Толи дело мой код читать - мм, произведение искусств! Хочется, чтобы это дело проходило быстро и не теряло качество. Чаще это были знакомые, но давно обсужденные задачи и иногда что-то совершенно новое, прошедшее мимо меня на этапе Дискавери. Всегда помогало грамотное описание задач - given-when-then были спасением. Прочитать код сверху вниз и механически выявить проблемы с дизайном это одно. Понять через призму кусков кода раздоженных по проекту что эта фича добавляет, в что возможно ломает - это другое. К задачам, где я был тех оунером я просил всегда добавлять компонентные тесты - чтобы я видел инпут и отпут и смог бы сориентироваться и понять о чем фича, что она вносит. Таким образом я не повторяя работу статических анализаторов смотрел дизайн - «где и какой код положили», что тестируется и как изменилось поведение. И на этом все ревью. Обычно на задачу, над которой работал человек 3-5 дней я тратил 15 минут. 

Баги
Бывает что по описанию ошибки или стектрецса ты сразу понимаешь в чем беда. Например NPE, понятно что где-то должно быть значное а не null и даже понятно место выстреливание. Но знаю ли я как выглядит схема потоков данных и код его обсцжливбаший, чтобы понять? Тут ужу проблема. Но начинаю обычно с того, что воспроизвожу баг компонентным тестом. Это часто кажется самым простым путем - я вижу лог входящего запроса в сервис и повторяю это в тесте. Если баг не воспроизводится и, то я глубже анализирую интеграции и настраиваю Моки в тестах согласно логам - тому как ответили смежные сервисы. Стоит отметить, что если где-то рядом уже есть компонентный тест связной фичи, то я копирую его и подставляю инпут и Моки согласно логам.

Особенно неприятны там, где 

Наблбдение1
Бывает что нет смысла запоминать реализацию - как код написан, потому что завтра коллега может это переписать и ты даже не поймешь. Подобное можно сказать и про поведение. Но вот в чем разница вероятность что поведение сервиса добавится что-то и кода высока. Но вот наврятли продукт такой «а давайте теперь

Что сервис создаёт профиль и сохраняет их базу по прежнему тоже что и было год назад, а код внутри переписывали множество раз - меня подход к мапингу (дозер, еще что-то , ручное) сервисы постояннтпереимновывали потому что с накоплением кода формировалось видение и логика, добавился drools и тд 

Я работал над сервисами для финтеха и облачный cpl не так уж сильно то и отличается. 

Онбординг 

Наступает аналитический ступор

Документация - апи, друлс или бизнес правила

## Чему я научился

Нужна изоляция и если она протекает то все 
Они долгие нужно оптимизировать, например общий постгрес и отчего нужна изоляция
Изоляция это хорошо, из минуса плюс появился
Нужно много контекстов и спринг течет, вот раз два три репорты. Чинится так - ссылка на код. Теперь есть понимание, что там так занимает. Раньше просто увеличивали размер хипа, принимая это как данность. Теперь влезаем в 512.

## Часто тесты пишут так

Часто тесты пишут так: берут код, начинают ее излагать и в конце работы, если повезет, добавляют тесты. Такие тесты нужно либо сочинять с нуля, либо притягивать за уши.
Одно сложно, второе — неубедительно.
Гораздо проще писать код, когда тест уже появился, сам приплыл вам в руки. И взять его нужно из описания. Обычно в задачах формулируют did, dor , given when then. Если у вас компонентные, то вам не нужно иметь готовое решение, чтобы написать тест - у вас есть приложение, его вход и выход, просто опишите в тесте сценарии которые важны, чтобы считать задачу сделанной. На данном этапе вы работаете с требованиями и приемкой, не думаете о детялях реализации. 
Если делать иначе, написать код, то захочется уже отдать скорее задачу и выдохнуть. Ощущение заверешнной работы будет на вас давить и вы это раздражение перенесете на тесты. Я часто слышал «блин, задачу сделал, еще и тесты теперь писать! Как это бесит». Но ведь тесты это часть сопровождающей поддержки. Мы ведь не пишем код, мы участвуем в разработке. 
При этом процесс работы над требованиями уже есть, достойно лишь сопроводить эту работу артефактами. Запишите свои мысли и ожидания от сервиса в виде тестов. Сделайте аналитическую работу сразу, первым этапом и дальше можете писать код. 
Что делать, если не понимаешь с чего начать, нет компонентных тестов вообще и это все сложно. Я поделаю начать с исключения ручного процесса тестирования разработчиком из цикла разработчики.

Давайте разберем пример - сохранение профиля клиента. У нас есть post и есть get для получения данных. Мы пишем тест: . Наверное именно это я бы и проверил руками после завершения работы. 

Исключение ручного тестирования 
Знакома ли вам ситуация, когда после завершения работы над фичей вы открываете постман (или что-то аналогичное) и начинается долго и нужно протыкивать вручную сценарии. Если вы начинающий разработчик, вам возможно это нравится - видите как формируется ответ и ваша фича оживает. Соу эксайтед! Но если вы опытный разработчик, то вас скорее всего это уже набило оскомину. В моем случае мне это настолько надоело, что я стал постепенно вместе с задачами комитить небольшие компонентные тесты с уенариями, что прогоняю руками. Коллеги наврядли вначале могли оценить это - ну делает и делает. Но потом, когда они работали с чем-то рядом, они могли как минимум не сломать что-то, что я делал. Через какое-то время в сервисе было уже достаточное количество таких тестов и самое главное зачатки dsl, потому что сценарии то однотипны - летит такой джсон и вылетает вот такой. Нужно сравнить. В итоге я выкинул постман из своей разработчик.

## Терминалогия

[[Тесты]]

Компонентные тесты - тесты, которые проверяют поведение одного компонента приложения, используя реальные неуправляемые внепроцессные зависимости типа "внешние сервисы".

Изолированные компонентные тесты - тесты, которые проверяют поведение одного компонента приложения, используя моки неуправляемых внепроцессных зависимостей. В роли SUT в данном случае выступает всё приложение. В подобных тестах допускается исключение части функциональности через mock - это компромисс между полнотой проверки и скоростью/стабильностью тестов.

E2E-тесты (end-to-end tests) - проверка методом чёрного ящика бизнес сценариев работы приложения с точки зрения конечного пользователя на реальном стенде (preprod, prod).

## Какой тест выбрать

Как и везде в редактуре, относитесь к таким под-лежащим и сказуемым не как к закону, а как к инструментам - как к линейке или молотку. Мы используем их не потому, что это хорошо и правильно, а потому, что это помогает нам в решении нашей задачи. Само по себе это никак.
Бессмысленно задаваться вопросом вроде «Сколько раз можно использовать молоток в этой задаче?». Гораздо полезнее думать, какая у нас задача и какими инструментами ее лучше решить.
Чего мы хотим — показать действие или неподвижную кар-тинку? Мы хотим нарисовать в голове читателя захватывающую сцену из кинофильма или напустить тумана? Мы хотим зажечь его воображение или усыпить внимание?

## Вывод

Время выполнения теста должно быть пропорционально тбьекту, не sut, а бьекту - то что мы тестируем, меток, фича

#article #testing #testing_trophy #draft